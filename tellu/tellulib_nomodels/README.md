# TelluLib Nomodels
Control experiments - EvoSuite test generation without Botsing model generation

Running in Git Bash on Windows 10.
Running in tellulib project folder, with a copy of evosuite in bin sub-folder, taken from the evosuite-model-seeding-tutorial.
Coverage computed with OpenClover 4.3.1 Eclipse plugin.
Mutation score computed with PIT 1.4.7, Descartes 1.2.5 mutation engine (from Maven, with stamp profile).

## Procedure
We follow the same procedure as in the EvoSuite Behavioral Models Seeding experiments, with the exception of Botsing model generation. Commands in tellulib project folder.

```bash
mvn clean install

mvn org.apache.maven.plugins:maven-dependency-plugin:copy-dependencies

mvn dependency:build-classpath

export tellulib_classpath="target/classes;target/dependency/commons-codec-1.9.jar;target/dependency/httpclient-4.5.5.jar;target/dependency/httpcore-4.4.9.jar;target/dependency/commons-logging-1.2.jar;target/dependency/junit-4.12.jar;target/dependency/hamcrest-core-1.3.jar"
```

We generate tests with EvoSuite, for the same classes as in the Botsing model seeding experiments, just leaving out the model_path argument. Example below for DataModel. See Results for list of selected classes.
```bash
java -d64 -Xmx4000m -jar bin/evosuite-master-1.0.7-SNAPSHOT.jar \
	-class "no.tellu.lib.data.model.DataModel" \
	-projectCP "$tellulib_classpath" \
	-generateMOSuite \
	-Dalgorithm=DynaMOSA \
	-Dsearch_budget=120 \
	-Dseed_clone="0.5" \
	-Donline_model_seeding=TRUE \
	-Dtest_dir="results/tellulib/evosuite-tests" \
	-Dreport_dir="results/tellulib/evosuite-report" \
	-Dno_runtime_dependency=true
```

All generated tests are copied into the project and checked, removing faulty tests. Some generated tests have EvoSuite dependencies. A test dependency to evosuite-master 1.0.6 was added to the pom file.

We run Clover from Eclipse and PIT/Descartes from Maven, to compute scores to compare with the Botsing model seeding results.

```bash
mvn org.pitest:pitest-maven:mutationCoverage -Pstamp
```

## Results
Test generation was successful for all selected classes in data.

DataModel:
Generated 171 tests. 3 time out, one throws NullPointerException.
167 working.

DataHandleImpl:
Generated 160 tests. 157 working.

DataModelHandle:
Generated 101 tests, all working.

DataTemplate:
Generated 26 tests. 25 working.

MultiLevelHandle:
Generated 28 tests, all working.

MergeHandle:
Generated 69 tests. 64 working.

DataGroupNode:
Generated 163 tests. 161 working.

DataValueNode:
Generated 138 tests. 135 working.

Total working generated: 838

Total tests after adding all generated tests which pass: 915

Coverage by Clover - after
Unit tests: 915
Coverage: 65,9% (vs 64,6% with model seeding)

Mutation score by Descartes - after
Mutation score: 59% (vs 58% with model seeding)
Issues: 44 (7 paritally-tested, 37 pseudo-tested) vs 52 with model seeding

We see that, compared to using the models generated by Botsing, we actually get slightly better results without them. We get more tests, and slightly better coverage (65,9% vs 64,6%) and mutation score (59% vs 58%).

We have also looked at the time to generate tests, as reported in results\tellulib\evosuite-report.

For DataModel:
* Time without models: 171 sec.
* Time with models: 180 sec.

For DataHandleImpl:
* Time without models: 133 sec.
* Time with models: 132 sec.

For DataModelHandle:
* Time without models: 132 sec.
* Time with models: 132 sec.

The differences are not really significant when considering there is some random variation.
